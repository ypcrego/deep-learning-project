{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cf78b4e9",
      "metadata": {
        "id": "cf78b4e9"
      },
      "source": [
        "# Atividade: CNNs para Classificação\n",
        "\n",
        "Neste notebook, iremos preparar nosso próprio dataset e treinar um modelo de classificação de imagens."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "108587c0",
      "metadata": {
        "id": "108587c0"
      },
      "source": [
        "## Preparando os dados\n",
        "\n",
        "Os dados desta atividade serão baixados da internet. Utilizaremos para isso buscadores comuns. Em seguida, dividiremos em treinamento e validação."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "id": "4916745d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4916745d",
        "outputId": "d0909693-63f4-49e4-c1ed-d667169f8f9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 4, in <module>\n",
            "    from pip._internal.cli.main import main\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/main.py\", line 11, in <module>\n",
            "    from pip._internal.cli.autocompletion import autocomplete\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/autocompletion.py\", line 10, in <module>\n",
            "    from pip._internal.cli.main_parser import create_main_parser\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/main_parser.py\", line 9, in <module>\n",
            "    from pip._internal.build_env import get_runnable_pip\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/build_env.py\", line 19, in <module>\n",
            "    from pip._internal.cli.spinners import open_spinner\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/spinners.py\", line 9, in <module>\n",
            "    from pip._internal.utils.logging import get_indentation\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/utils/logging.py\", line 13, in <module>\n",
            "    from pip._vendor.rich.console import (\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/rich/console.py\", line 51, in <module>\n",
            "    from ._log_render import FormatTimeCallable, LogRender\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/rich/_log_render.py\", line 5, in <module>\n",
            "    from .text import Text, TextType\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/rich/text.py\", line 21, in <module>\n",
            "    from .align import AlignMethod\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/rich/align.py\", line 10, in <module>\n",
            "    from .constrain import Constrain\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/rich/constrain.py\", line 4, in <module>\n",
            "    from .measure import Measurement\n",
            "  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1322, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 1262, in _find_spec\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 1532, in find_spec\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 1506, in _get_spec\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 1639, in find_spec\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 1594, in _get_spec\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 842, in spec_from_file_location\n",
            "  File \"<frozen importlib._bootstrap>\", line 599, in __init__\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 10, in <module>\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/main.py\", line 78, in main\n",
            "    command = create_command(cmd_name, isolated=(\"--isolated\" in cmd_args))\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/commands/__init__.py\", line 114, in create_command\n",
            "    module = importlib.import_module(module_path)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/importlib/__init__.py\", line 90, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 999, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/commands/install.py\", line 47, in <module>\n",
            "    from pip._internal.wheel_builder import build, should_build_for_install_command\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/wheel_builder.py\", line 19, in <module>\n",
            "    from pip._internal.operations.build.wheel_editable import build_wheel_editable\n",
            "  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 995, in exec_module\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 1128, in get_code\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 757, in _compile_bytecode\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3864156616.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'install icrawler --quiet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'install pyimagedl --quiet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'install seaborn --quiet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2416\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_local_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2417\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2418\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2419\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_installation_commands.py\u001b[0m in \u001b[0;36m_pip_magic\u001b[0;34m(line)\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0;31m# Colab is set up such that pip does the right thing, and pip install\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m   \u001b[0;31m# will properly trigger the pip install warning.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m       \u001b[0m_pip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_previous_import_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_send_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36mprint_previous_import_warning\u001b[0;34m(output)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprint_previous_import_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   \u001b[0;34m\"\"\"Prints a warning about previously imported packages.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m   \u001b[0mpackages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_previously_imported_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpackages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# display a list of packages using the colab-display-data mimetype, which\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36m_previously_imported_packages\u001b[0;34m(pip_output)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_previously_imported_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpip_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m   \u001b[0;34m\"\"\"List all previously imported packages from a pip install.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m   \u001b[0minstalled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_extract_toplevel_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpip_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstalled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36m_extract_toplevel_packages\u001b[0;34m(pip_output)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;34m\"\"\"Extract the list of toplevel packages associated with a pip install.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0mtoplevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mps\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpackages_distributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m       \u001b[0mtoplevel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mpackages_distributions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    945\u001b[0m     \u001b[0mpkg_to_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mpkg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_top_level_declared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_top_level_inferred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m             \u001b[0mpkg_to_dist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpkg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkg_to_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36m_top_level_inferred\u001b[0;34m(dist)\u001b[0m\n\u001b[1;32m    957\u001b[0m     opt_names = {\n\u001b[1;32m    958\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetmodulename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0malways_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m     }\n\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mfiles\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m         return skip_missing_files(\n\u001b[0m\u001b[1;32m    501\u001b[0m             make_files(\n\u001b[1;32m    502\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_files_distinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/_functools.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(param, *args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mskip_missing_files\u001b[0;34m(package_paths)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mpass_none\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mskip_missing_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         return skip_missing_files(\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mpass_none\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mskip_missing_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         return skip_missing_files(\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36mexists\u001b[0;34m(self, follow_symlinks)\u001b[0m\n\u001b[1;32m    858\u001b[0m         \"\"\"\n\u001b[1;32m    859\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ignore_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36mstat\u001b[0;34m(self, follow_symlinks)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mdoes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \"\"\"\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "%pip install icrawler --quiet\n",
        "%pip install pyimagedl --quiet\n",
        "%pip install seaborn --quiet\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZCP_4kRykQF2",
      "metadata": {
        "id": "ZCP_4kRykQF2"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "\n",
        "def set_seed(seed=42):\n",
        "    \"\"\"Congela a aleatoriedade para tornar o experimento reprodutível.\"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "# Configuração de dispositivo\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Usando dispositivo: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b74ce50",
      "metadata": {
        "id": "7b74ce50"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from google.colab import drive\n",
        "#from icrawler.builtin import GoogleImageCrawler, BingImageCrawler"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b98d4ebb",
      "metadata": {
        "id": "b98d4ebb"
      },
      "source": [
        "### Adquirindo as Imagens\n",
        "\n",
        "Utilizaremos o iCrawler para baixar imagens em buscadores através de termos especificados. Defina sua lista de classes."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get images either from Drive or local storage\n",
        "use_local = False"
      ],
      "metadata": {
        "id": "qDWcwM54-TDV"
      },
      "id": "qDWcwM54-TDV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb2c5e01",
      "metadata": {
        "id": "bb2c5e01"
      },
      "outputs": [],
      "source": [
        "from imagedl import imagedl\n",
        "\n",
        "def download_images_generic(keyword, label, output_dir=\"data\", target_total=100):\n",
        "    final_folder = os.path.join(output_dir, label)\n",
        "    os.makedirs(final_folder, exist_ok=True)\n",
        "\n",
        "    # Conta imagens já existentes\n",
        "    count_existing = len([\n",
        "        f for f in os.listdir(final_folder)\n",
        "        if f.lower().endswith(('.jpg', '.png', '.jpeg', '.webp'))\n",
        "    ])\n",
        "\n",
        "    if count_existing >= target_total:\n",
        "        print(f\"✅ [{label}] Já possui {count_existing} imagens. Pulando...\")\n",
        "        return\n",
        "\n",
        "    needed = target_total - count_existing\n",
        "    print(f\"⬇️ [{label}] Possui {count_existing}. Baixando mais {needed} imagens...\")\n",
        "\n",
        "    temp_folder = final_folder + \"_tmp\"\n",
        "    if os.path.exists(temp_folder):\n",
        "        shutil.rmtree(temp_folder)\n",
        "\n",
        "    try:\n",
        "        # Configuração do cliente\n",
        "        client = imagedl.ImageClient(\n",
        "            image_source='GoogleImageClient',\n",
        "            init_image_client_cfg={'work_dir': temp_folder},\n",
        "            # Baixamos um pouco a mais para garantir caso alguns falhem\n",
        "            search_limits=needed + 30,\n",
        "            num_threadings=4,\n",
        "        )\n",
        "\n",
        "        # Busca e download\n",
        "        image_infos = client.search(keyword, search_limits_overrides=needed + 30)\n",
        "        client.download(image_infos=image_infos)\n",
        "\n",
        "        moved = 0\n",
        "        new_count = count_existing\n",
        "\n",
        "        # Move e renomeia as imagens do temp para a pasta final\n",
        "        for root, dirs, files in os.walk(temp_folder):\n",
        "            for file in files:\n",
        "                if moved >= needed:\n",
        "                    break\n",
        "\n",
        "                if file.lower().endswith(('.jpg', '.jpeg', '.png', '.webp')):\n",
        "                    src = os.path.join(root, file)\n",
        "                    # Formato: mondstadt_0001.jpg, liyue_0050.jpg, etc.\n",
        "                    dst = os.path.join(final_folder, f\"{label}_{new_count:04d}.jpg\")\n",
        "                    try:\n",
        "                        shutil.move(src, dst)\n",
        "                        moved += 1\n",
        "                        new_count += 1\n",
        "                    except:\n",
        "                        pass\n",
        "\n",
        "        print(f\"Concluído! Agora [{label}] tem {new_count} imagens.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao baixar imagens para {label}: {e}\")\n",
        "    finally:\n",
        "        if os.path.exists(temp_folder):\n",
        "            shutil.rmtree(temp_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mngutloVmzsW",
      "metadata": {
        "id": "mngutloVmzsW"
      },
      "outputs": [],
      "source": [
        "# -------------------------------------------------------------\n",
        "# CONFIGURAÇÃO PARA O PROJETO GENSHIN\n",
        "# -------------------------------------------------------------\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/genshin_landscape_dataset\"\n",
        "\n",
        "# Estratégia: Definimos as sub-regiões visuais distintas aqui.\n",
        "# O modelo vai aprender \"Enkanomiya\", \"Dragonspine\", etc.\n",
        "classes = {\n",
        "    # MONDTADT\n",
        "    \"mondstadt\": \"genshin impact mondstadt landscape scenery -character -build\",\n",
        "    \"dragonspine\": \"genshin impact dragonspine landscape scenery snow -character\",\n",
        "\n",
        "    # LIYUE\n",
        "    \"liyue\": \"genshin impact liyue  landscape scenery -character\",\n",
        "    \"the_chasm\": \"genshin impact the chasm underground landscape -character\",\n",
        "\n",
        "    # INAZUMA\n",
        "    \"inazuma\": \"genshin impact inazuma landscape scenery -character\",\n",
        "    \"enkanomiya\": \"genshin impact enkanomiya landscape scenery -character\",\n",
        "\n",
        "    # SUMERU\n",
        "    \"sumeru\": \"genshin impact sumeru landscape -character\",\n",
        "    \"sumeru_desert\": \"genshin impact sumeru desert landscape -character\",\n",
        "\n",
        "    # FONTAINE\n",
        "    \"fontaine\": \"genshin impact fontaine  landscape scenery -character\",\n",
        "    \"fontaine_underwater\": \"genshin impact fontaine underwater scenery -character\"\n",
        "}\n",
        "\n",
        "TARGET_IMAGES = 150\n",
        "\n",
        "# Loop de execução\n",
        "print(\"--- Iniciando Download dos Cenários de Genshin Impact ---\")\n",
        "#for label, keyword in classes.items():\n",
        "#    download_images_generic(keyword, label, output_dir=OUTPUT_DIR, target_total=TARGET_IMAGES)\n",
        "\n",
        "print(\"\\nProcesso finalizado!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BVZbyapdmzVr",
      "metadata": {
        "id": "BVZbyapdmzVr"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "JJ1ENtsa7803",
      "metadata": {
        "id": "JJ1ENtsa7803"
      },
      "source": [
        "# Carregando imagens do drive"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d931e35",
      "metadata": {
        "id": "0d931e35"
      },
      "source": [
        "### Treinamento e Validação\n",
        "\n",
        "Dividiremos as imagens baixadas nas pastas `train` e `val`. Defina uma porcentagem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sACOpj_k35-y",
      "metadata": {
        "id": "sACOpj_k35-y"
      },
      "outputs": [],
      "source": [
        "def split_dataset_3way(root_dir, train_ratio=0.7, val_ratio=0.15, seed=42):\n",
        "    split_root = root_dir + \"_split\"\n",
        "    train_dir = os.path.join(split_root, \"train\")\n",
        "    val_dir   = os.path.join(split_root, \"val\")\n",
        "    test_dir  = os.path.join(split_root, \"test\")\n",
        "\n",
        "    # SE JÁ EXISTE, NÃO FAZ NADA (Segurança)\n",
        "    if os.path.exists(split_root) and len(os.listdir(split_root)) > 0:\n",
        "        print(f\"Dataset já dividido em: {split_root}\")\n",
        "        return train_dir, val_dir, test_dir\n",
        "\n",
        "    print(\"Iniciando divisão do dataset...\")\n",
        "    for dir_path in [train_dir, val_dir, test_dir]:\n",
        "        os.makedirs(dir_path, exist_ok=True)\n",
        "\n",
        "    random.seed(seed)\n",
        "    # Lista classes ordenadas para garantir consistência\n",
        "    classes = sorted([d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))])\n",
        "\n",
        "    for class_name in classes:\n",
        "        src_path = os.path.join(root_dir, class_name)\n",
        "        images = sorted([f for f in os.listdir(src_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
        "        random.shuffle(images)\n",
        "\n",
        "        n_total = len(images)\n",
        "        n_train = int(n_total * train_ratio)\n",
        "        n_val   = int(n_total * val_ratio)\n",
        "\n",
        "        # Criar subpastas\n",
        "        os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)\n",
        "        os.makedirs(os.path.join(val_dir, class_name), exist_ok=True)\n",
        "        os.makedirs(os.path.join(test_dir, class_name), exist_ok=True)\n",
        "\n",
        "        # Copiar arquivos\n",
        "        for img in images[:n_train]:\n",
        "            shutil.copy(os.path.join(src_path, img), os.path.join(train_dir, class_name, img))\n",
        "        for img in images[n_train : n_train + n_val]:\n",
        "            shutil.copy(os.path.join(src_path, img), os.path.join(val_dir, class_name, img))\n",
        "        for img in images[n_train + n_val:]:\n",
        "            shutil.copy(os.path.join(src_path, img), os.path.join(test_dir, class_name, img))\n",
        "\n",
        "        print(f\"  [{class_name}] {n_train} Train, {n_val} Val, {n_total - n_train - n_val} Test\")\n",
        "\n",
        "    return train_dir, val_dir, test_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PD6EfgfV9nMB",
      "metadata": {
        "id": "PD6EfgfV9nMB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# ==============================================================================\n",
        "# 1. CONFIGURAÇÃO\n",
        "# ==============================================================================\n",
        "# Caminho da pasta\n",
        "SOURCE_PATH = \"genshin_landscape_dataset\"\n",
        "\n",
        "# Onde vamos salvar a versão organizada (treino/teste)\n",
        "SPLIT_ROOT = \"dataset_split_final\"\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. FUNÇÃO DE DIVISÃO (Caso a pasta venha \"crua\")\n",
        "# ==============================================================================\n",
        "def split_dataset_local(root_dir, target_root, train_ratio=0.7, val_ratio=0.15):\n",
        "    # Cria pastas de destino\n",
        "    for x in ['train', 'val', 'test']:\n",
        "        os.makedirs(os.path.join(target_root, x), exist_ok=True)\n",
        "\n",
        "    # Lista as classes (pastas dentro do dataset)\n",
        "    classes = [d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n",
        "\n",
        "    classes.sort()\n",
        "\n",
        "    if not classes:\n",
        "        print(f\"❌ ERRO: Nenhuma pasta de classe encontrada dentro de {root_dir}\")\n",
        "        return\n",
        "\n",
        "    print(f\"Iniciando divisão do dataset...\")\n",
        "\n",
        "    for class_name in classes:\n",
        "        class_dir = os.path.join(root_dir, class_name)\n",
        "        images = [f for f in os.listdir(class_dir) if f.lower().endswith(('.jpg', '.png', '.jpeg', '.webp'))]\n",
        "\n",
        "        images.sort()\n",
        "\n",
        "        # Embaralha para garantir aleatoriedade\n",
        "        random.shuffle(images)\n",
        "\n",
        "        # Calcula quantidades\n",
        "        n_total = len(images)\n",
        "        n_train = int(n_total * train_ratio)\n",
        "        n_val = int(n_total * val_ratio)\n",
        "\n",
        "        # Define splits\n",
        "        splits = {\n",
        "            'train': images[:n_train],\n",
        "            'val':   images[n_train:n_train+n_val],\n",
        "            'test':  images[n_train+n_val:]\n",
        "        }\n",
        "\n",
        "        # Copia os arquivos\n",
        "        for split_name, split_imgs in splits.items():\n",
        "            dest_dir = os.path.join(target_root, split_name, class_name)\n",
        "            os.makedirs(dest_dir, exist_ok=True)\n",
        "            for img in split_imgs:\n",
        "                shutil.copy(os.path.join(class_dir, img), os.path.join(dest_dir, img))\n",
        "\n",
        "        print(f\"  [{class_name}] Total: {n_total} -> Train: {len(splits['train'])} | Val: {len(splits['val'])} | Test: {len(splits['test'])}\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 3. LÓGICA PRINCIPAL\n",
        "# ==============================================================================\n",
        "\n",
        "if use_local:\n",
        "  if not os.path.exists(SOURCE_PATH):\n",
        "      print(f\"❌ A pasta '{SOURCE_PATH}' não foi encontrada!\")\n",
        "  else:\n",
        "      # Verifica se a pasta já tem 'train' e 'val' dentro (se já veio pronta)\n",
        "      contents = os.listdir(SOURCE_PATH)\n",
        "      if 'train' in contents and 'val' in contents:\n",
        "          print(\"✅ Estrutura pronta detectada (pastas train/val já existem).\")\n",
        "          TRAIN_DIR = os.path.join(SOURCE_PATH, 'train')\n",
        "          VAL_DIR = os.path.join(SOURCE_PATH, 'val')\n",
        "          TEST_DIR = os.path.join(SOURCE_PATH, 'test') if 'test' in contents else VAL_DIR\n",
        "      else:\n",
        "          print(\"⚠️ Estrutura 'crua' detectada. Realizando divisão automática...\")\n",
        "          # Limpa destino anterior se existir\n",
        "          if os.path.exists(SPLIT_ROOT): shutil.rmtree(SPLIT_ROOT)\n",
        "\n",
        "          # Executa a divisão\n",
        "          split_dataset_local(SOURCE_PATH, SPLIT_ROOT)\n",
        "\n",
        "          TRAIN_DIR = os.path.join(SPLIT_ROOT, 'train')\n",
        "          VAL_DIR = os.path.join(SPLIT_ROOT, 'val')\n",
        "          TEST_DIR = os.path.join(SPLIT_ROOT, 'test')\n",
        "\n",
        "      # Confirmação final\n",
        "      print(\"\\n--- Caminhos Configurados ---\")\n",
        "      print(f\"Train: {TRAIN_DIR}\")\n",
        "      print(f\"Val:   {VAL_DIR}\")\n",
        "      print(f\"Test:  {TEST_DIR}\")\n",
        "else:\n",
        "  drive.mount('/content/drive')\n",
        "  TRAIN_DIR, VAL_DIR, TEST_DIR = split_dataset_3way(OUTPUT_DIR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9974e910",
      "metadata": {
        "id": "9974e910"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "Implemente um Dataset PyTorch que carregue as imagens baixadas com suas respectivas classes. Aplique data augmentation e carregue em batches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f91b901e",
      "metadata": {
        "id": "f91b901e"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "h_N2vK03xXAz",
      "metadata": {
        "id": "h_N2vK03xXAz"
      },
      "outputs": [],
      "source": [
        "# Augmentation para TREINO (Variações para aprender melhor)\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)), # Zoom aleatório\n",
        "    transforms.RandomHorizontalFlip(p=0.5),              # Espelhamento Horizontal\n",
        "    transforms.RandomRotation(degrees=15),               # Rotação leve\n",
        "    #transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.02), # Hue baixo!\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Para VALIDAÇÃO e TESTE (Apenas redimensionar e normalizar)\n",
        "val_test_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Datasets\n",
        "train_dataset = datasets.ImageFolder(TRAIN_DIR, transform=train_transforms)\n",
        "val_dataset   = datasets.ImageFolder(VAL_DIR,   transform=val_test_transforms)\n",
        "test_dataset  = datasets.ImageFolder(TEST_DIR,  transform=val_test_transforms)\n",
        "\n",
        "# DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader   = DataLoader(val_dataset,   batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "print(f\"Classes: {train_dataset.classes}\")\n",
        "print(\"Total treino:\", len(train_dataset))\n",
        "print(\"Total validação:\", len(val_dataset))\n",
        "\n",
        "images, labels = next(iter(train_loader))\n",
        "print(\"Batch shape:\", images.shape)\n",
        "print(\"Labels:\", labels[:10])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "z89T_jkzt587",
      "metadata": {
        "id": "z89T_jkzt587"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83ab6c9e",
      "metadata": {
        "id": "83ab6c9e"
      },
      "source": [
        "## Definição do Modelo\n",
        "\n",
        "Defina aqui o modelo que será utilizado, sendo implementação própria ou um modelo pré-treinado. Teste diversas arquiteturas diferentes e verifique qual delas tem melhor desempenho em validação."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7634074",
      "metadata": {
        "id": "f7634074"
      },
      "outputs": [],
      "source": [
        "import torchvision.models as models\n",
        "import torch.nn as nn # Adicionar esta linha para importar o módulo nn\n",
        "\n",
        "NUM_CLASSES = 10\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# B — MobileNetV2 (transfer learning — rápido e eficiente)\n",
        "# ----------------------------------------------------------\n",
        "def build_mobilenet(num_classes):\n",
        "    model = models.mobilenet_v2(weights=\"IMAGENET1K_V1\")\n",
        "\n",
        "    for param in model.features.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "    model.classifier[1] = nn.Linear(model.last_channel, num_classes)\n",
        "    return model\n",
        "\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# D — EfficientNet-B0 (ótima acurácia com baixo custo)\n",
        "# ----------------------------------------------------------\n",
        "def build_efficientnet(num_classes, dropout_rate=0.2):\n",
        "    model = models.efficientnet_b0(weights=\"IMAGENET1K_V1\")\n",
        "\n",
        "    for param in model.features.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "    for param in model.features[-3:].parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "    in_features = model.classifier[1].in_features\n",
        "    model.classifier = nn.Sequential(\n",
        "        nn.Dropout(p=dropout_rate, inplace=True),\n",
        "        nn.Linear(in_features, num_classes),\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# ----------------------------------------------------------\n",
        "# Função auxiliar para escolher o modelo\n",
        "# ----------------------------------------------------------\n",
        "def get_model(name, num_classes, dropout_rate=0.2):\n",
        "    name = name.lower()\n",
        "    if name == \"mobilenet\":\n",
        "        return build_mobilenet(num_classes)\n",
        "    elif name == \"efficientnet\":\n",
        "        return build_efficientnet(num_classes, dropout_rate)\n",
        "    else:\n",
        "        raise ValueError(\"Model name inválido.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dabbee06",
      "metadata": {
        "id": "dabbee06"
      },
      "source": [
        "## Treinamento\n",
        "\n",
        "Defina a função de custo e o otimizador do modelo. Em seguida, implemente o código de treinamento e treine-o. Ao final, exiba as curvas de treinamento e validação para a loss e a acurácia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f234eaa",
      "metadata": {
        "id": "8f234eaa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=3, min_delta=0):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): Quantas épocas esperar sem melhoria antes de parar.\n",
        "            min_delta (float): Mínima mudança para considerar como melhoria.\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.min_delta = min_delta\n",
        "        self.counter = 0\n",
        "        self.best_loss = None\n",
        "        self.early_stop = False\n",
        "        self.best_model_state = None\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        if self.best_loss is None:\n",
        "            self.best_loss = val_loss\n",
        "            self.best_model_state = model.state_dict() # Salva o estado inicial\n",
        "        elif val_loss > self.best_loss - self.min_delta:\n",
        "            # Não melhorou o suficiente\n",
        "            self.counter += 1\n",
        "            print(f'EarlyStopping counter: {self.counter} de {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            # Melhorou - Resetar contador e salvar novo melhor\n",
        "            self.best_loss = val_loss\n",
        "            self.best_model_state = model.state_dict()\n",
        "            self.counter = 0\n",
        "\n",
        "    def load_best_weights(self, model):\n",
        "        # Restaura os pesos da melhor época encontrada\n",
        "        model.load_state_dict(self.best_model_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lC9U5ZxgzIXj",
      "metadata": {
        "id": "lC9U5ZxgzIXj"
      },
      "outputs": [],
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import torch.optim as optim # Adicionar esta linha para importar o otimizador\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Função de treino + validação\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "def train_model(model, train_loader, val_loader, epochs=20, lr=1e-4, save_name=\"best_model.pth\", patience=3, use_early_stopping=False, use_scheduler=False):\n",
        "\n",
        "    early_stopping = None\n",
        "    if use_early_stopping:\n",
        "        early_stopping = EarlyStopping(patience=patience, min_delta=1e-4)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    scheduler = None\n",
        "    if use_scheduler:\n",
        "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2)\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accs = []\n",
        "    val_accs = []\n",
        "    lrs = []\n",
        "\n",
        "    best_val_acc = 0.0\n",
        "    last_lr = lr\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\nEPOCH {epoch+1}/{epochs}\")\n",
        "        model.train()\n",
        "\n",
        "        epoch_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        # -------------------- TREINO --------------------\n",
        "        pbar = tqdm(train_loader, desc=\"Training\", leave=False)\n",
        "        for imgs, labels in pbar:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "        train_acc = correct / total\n",
        "        train_loss = epoch_loss / len(train_loader)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        train_accs.append(train_acc)\n",
        "\n",
        "        # -------------------- VALIDAÇÃO --------------------\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for imgs, labels in val_loader:\n",
        "                imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "                outputs = model(imgs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_loss += loss.item()\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                val_correct += (preds == labels).sum().item()\n",
        "                val_total += labels.size(0)\n",
        "\n",
        "        val_acc = val_correct / val_total\n",
        "        val_loss = val_loss / len(val_loader)\n",
        "\n",
        "        val_losses.append(val_loss)\n",
        "        val_accs.append(val_acc)\n",
        "\n",
        "        print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
        "        print(f\"Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc:.4f}\")\n",
        "        if scheduler:\n",
        "            scheduler.step(val_loss)\n",
        "            current_lr = optimizer.param_groups[0]['lr']\n",
        "            lrs.append(current_lr)\n",
        "            if current_lr != last_lr:\n",
        "                print(f\"Learning Rate diminuiu: {last_lr:.1e} -> {current_lr:.1e}\")\n",
        "                last_lr = current_lr\n",
        "\n",
        "        if early_stopping:\n",
        "            early_stopping(val_loss, model)\n",
        "            if early_stopping.early_stop:\n",
        "                print(\"Stopping early. Model has stopped improving.\")\n",
        "                break\n",
        "\n",
        "        # ---------------- Salvar melhor modelo ----------------\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            torch.save(model.state_dict(), save_name)\n",
        "            print(f\"Modelo salvo com Acc: {best_val_acc:.4f}\")\n",
        "\n",
        "    # salvar checkpoint final\n",
        "    print(\"-\" * 30)\n",
        "    if best_val_acc > 0:\n",
        "      print(f\"Carregando o melhor modelo do disco (Acc: {best_val_acc:.4f})...\")\n",
        "      model.load_state_dict(torch.load(save_name))\n",
        "    else:\n",
        "      print(\"\\nO modelo não melhorou em nenhuma época\")\n",
        "\n",
        "    return train_losses, val_losses, train_accs, val_accs, lrs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "t-FbcU99yuZ2",
      "metadata": {
        "id": "t-FbcU99yuZ2"
      },
      "outputs": [],
      "source": [
        "def train_and_evaluate(model_name, model, train_loader, val_loader, epochs=20, lr=1e-4, patience=3, use_early_stopping=False, use_scheduler=False):\n",
        "\n",
        "    print(f\"\\n==============================\")\n",
        "    print(f\" Treinando modelo: {model_name}\")\n",
        "    print(f\"==============================\")\n",
        "\n",
        "    filename = f\"best_model_{model_name}.pth\"\n",
        "\n",
        "    train_losses, val_losses, train_accs, val_accs, lrs = train_model(\n",
        "        model,\n",
        "        train_loader,\n",
        "        val_loader,\n",
        "        epochs=epochs,\n",
        "        lr=lr,\n",
        "        save_name=filename,\n",
        "        patience=patience,\n",
        "        use_early_stopping=use_early_stopping,\n",
        "        use_scheduler=use_scheduler\n",
        "    )\n",
        "\n",
        "    best_val_acc = max(val_accs)\n",
        "\n",
        "    return {\n",
        "        \"name\": model_name,\n",
        "        \"train_losses\": train_losses,\n",
        "        \"val_losses\": val_losses,\n",
        "        \"train_accs\": train_accs,\n",
        "        \"val_accs\": val_accs,\n",
        "        \"best_val_acc\": best_val_acc,\n",
        "        \"lrs\": lrs\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BNrMMULfy2b6",
      "metadata": {
        "id": "BNrMMULfy2b6"
      },
      "outputs": [],
      "source": [
        "models_to_test = {\n",
        "    #\"SimpleCNN\": get_model(\"cnn\"),\n",
        "    #\"MobileNetV2\": get_model(\"mobilenet\", num_classes=len(train_dataset.classes))\n",
        "    #\"ResNet50\": get_model(\"resnet50\")\n",
        "    \"EfficientNet\": get_model(\"efficientnet\", num_classes=len(train_dataset.classes), dropout_rate=0.4)\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UtxwKKR1y4Ql",
      "metadata": {
        "id": "UtxwKKR1y4Ql"
      },
      "outputs": [],
      "source": [
        "\n",
        "results = []\n",
        "\n",
        "\n",
        "for name, model in models_to_test.items():\n",
        "    model = model.to(device)\n",
        "    r = train_and_evaluate(name, model, train_loader,val_loader, epochs = 50, lr=1e-4, patience=8, use_early_stopping=True, use_scheduler=True)\n",
        "    results.append(r)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4Bkh-KGVy7V_",
      "metadata": {
        "id": "4Bkh-KGVy7V_"
      },
      "outputs": [],
      "source": [
        "print(\"\\n===== RESULTADO FINAL =====\\n\")\n",
        "for r in results:\n",
        "    print(f\"{r['name']:20s}  |  Best Val Acc: {r['best_val_acc']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "A5jaY1_my75p",
      "metadata": {
        "id": "A5jaY1_my75p"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib.ticker import FuncFormatter\n",
        "\n",
        "def plot_comparison(results):\n",
        "# Define o estilo visual \"Clean\"\n",
        "    sns.set_style(\"whitegrid\")\n",
        "\n",
        "    # Cores Profissionais\n",
        "    c_train = '#2980b9' # Azul Belize\n",
        "    c_val   = '#c0392b' # Vermelho Pomegranate\n",
        "    c_text  = '#2c3e50' # Cinza Escuro (quase preto)\n",
        "    c_lr    = '#8e44ad' # Roxo Wisteria (para o LR)\n",
        "\n",
        "    for res in results:\n",
        "        train_loss = res['train_losses']\n",
        "        val_loss = res['val_losses']\n",
        "        train_acc = res['train_accs']\n",
        "        val_acc = res['val_accs']\n",
        "\n",
        "        lrs = res.get('lrs')\n",
        "\n",
        "        epochs = range(1, len(train_loss) + 1)\n",
        "\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "        # --- GRÁFICO 1: LOSS ---\n",
        "        # Área de divergência (sombra leve onde Validação > Treino)\n",
        "        ax1.fill_between(epochs, train_loss, val_loss, color=c_val, alpha=0.05)\n",
        "\n",
        "        ax1.plot(epochs, train_loss, color=c_train, linestyle='--', linewidth=2, label='Treino', marker='o', markersize=4)\n",
        "        ax1.plot(epochs, val_loss, color=c_val, linewidth=2.5, label='Validação', marker='s', markersize=4)\n",
        "\n",
        "        ax1.set_title(\"Evolução da Perda (Loss)\", fontsize=14, fontweight='bold', color=c_text, pad=15)\n",
        "        ax1.set_xlabel(\"Épocas\", fontsize=11)\n",
        "        ax1.set_ylabel(\"Loss\", fontsize=11)\n",
        "        ax1.legend(frameon=True, facecolor='white', framealpha=0.9, loc='upper right')\n",
        "\n",
        "        # Remove bordas desnecessárias (topo e direita)\n",
        "        sns.despine(ax=ax1)\n",
        "\n",
        "        # Seta indicando o MELHOR momento (Menor Loss)\n",
        "        min_loss = min(val_loss)\n",
        "        idx_best = val_loss.index(min_loss)\n",
        "        best_epoch_loss = idx_best + 1\n",
        "        val_at_best = min_loss\n",
        "        train_at_best = train_loss[idx_best]\n",
        "\n",
        "        y_span = max(max(train_loss), max(val_loss)) - min(min(train_loss), min(val_loss))\n",
        "        offset = y_span * 0.15\n",
        "        marker_gap = y_span * 0.025 # Distância da PONTA DA SETA (o \"respiro\")\n",
        "\n",
        "        # Flags para controlar limites\n",
        "        text_goes_down = False\n",
        "\n",
        "        if train_at_best > val_at_best:\n",
        "            # Texto EMBAIXO, Seta aponta pra CIMA\n",
        "            # xy (ponta da seta) fica um pouco abaixo do valor real (min_loss - gap)\n",
        "            xy_point = (best_epoch_loss, val_at_best - marker_gap)\n",
        "            xy_text_pos = (best_epoch_loss, val_at_best - offset)\n",
        "            text_goes_down = True\n",
        "        else:\n",
        "            # Texto EM CIMA, Seta aponta pra BAIXO\n",
        "            # xy (ponta da seta) fica um pouco acima do valor real (min_loss + gap)\n",
        "            xy_point = (best_epoch_loss, val_at_best + marker_gap)\n",
        "            xy_text_pos = (best_epoch_loss, val_at_best + offset)\n",
        "\n",
        "        ax1.annotate(f'Melhor: {min_loss:.3f}', xy=xy_point, xytext=xy_text_pos,\n",
        "                     arrowprops=dict(facecolor=c_text, shrink=0.0, width=2, headwidth=8),\n",
        "                     color=c_text, ha='center', fontweight='bold',\n",
        "                     bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=c_text, alpha=0.8))\n",
        "\n",
        "        # --- SOLUÇÃO 2: EVITAR QUE O TEXTO SAIA DO GRÁFICO EMBAIXO ---\n",
        "        if text_goes_down:\n",
        "            ymin, ymax = ax1.get_ylim()\n",
        "            if xy_text_pos[1] < ymin:\n",
        "                ax1.set_ylim(bottom=xy_text_pos[1] - (y_span * 0.05))\n",
        "\n",
        "        # --- GRÁFICO 2: ACCURACY ---\n",
        "        ax2.plot(epochs, train_acc, color=c_train, linestyle='--', linewidth=2, label='Treino', marker='o', markersize=4)\n",
        "        ax2.plot(epochs, val_acc, color=c_val, linewidth=2.5, label='Validação', marker='s', markersize=4)\n",
        "\n",
        "        ax2.set_title(\"Evolução da Acurácia\", fontsize=14, fontweight='bold', color=c_text, pad=15)\n",
        "        ax2.set_xlabel(\"Épocas\", fontsize=11)\n",
        "        ax2.set_ylabel(\"Acurácia\", fontsize=11)\n",
        "        ax2.legend(frameon=True, facecolor='white', framealpha=0.9, loc='lower right')\n",
        "\n",
        "        sns.despine(ax=ax2)\n",
        "\n",
        "        # Seta indicando o PICO de performance\n",
        "        max_acc = max(val_acc)\n",
        "        best_epoch_acc = val_acc.index(max_acc) + 1\n",
        "\n",
        "        # Span da Accuracy para calcular gap proporcional\n",
        "        acc_span = max(val_acc) - min(val_acc) if max(val_acc) != min(val_acc) else 0.1\n",
        "        acc_offset = acc_span * 0.15\n",
        "        acc_gap = acc_span * 0.025\n",
        "\n",
        "        ax2.annotate(f'Pico: {max_acc*100:.1f}%', xy=(best_epoch_acc, max_acc - acc_gap), xytext=(best_epoch_acc, max_acc - acc_offset),\n",
        "                     arrowprops=dict(facecolor=c_text, shrink=0.0, width=2, headwidth=8),\n",
        "                     color=c_text, ha='center', fontweight='bold')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    # =========================================================\n",
        "    # NOVO CÓDIGO: GRÁFICO EXTRA DE LR (Eixo Duplo)\n",
        "    # =========================================================\n",
        "    if lrs is not None and len(lrs) > 0:\n",
        "      with plt.style.context('seaborn-v0_8'):\n",
        "        # Cria a figura e o primeiro eixo (Loss)\n",
        "        fig, ax_loss = plt.subplots(figsize=(10, 5))\n",
        "\n",
        "        # Título e Eixo X\n",
        "        ax_loss.set_title(f\"Impacto da Learning Rate na Loss ({res.get('name', 'Modelo')})\", fontsize=12)\n",
        "        ax_loss.set_xlabel(\"Epoch\")\n",
        "\n",
        "        # Eixo da Esquerda (Loss - Azul)\n",
        "        ax_loss.set_ylabel(\"Train Loss\", color=\"#1f77b4\", fontweight='bold') # Usei o azul padrão do seaborn\n",
        "        l1 = ax_loss.plot(epochs, train_loss, color=\"#1f77b4\", linewidth=2.5, label=\"Train Loss\") # Removi o 'o' (marker) para um look mais clean\n",
        "        ax_loss.tick_params(axis=\"y\", labelcolor=\"#1f77b4\")\n",
        "        ax_loss.grid(True, alpha=0.5, linestyle='--') # Grade mais suave\n",
        "\n",
        "        # Eixo da Direita (LR - Vermelho)\n",
        "        ax_lr = ax_loss.twinx() # Cria o eixo duplo\n",
        "        ax_lr.set_ylabel(\"Learning Rate\", color=\"#d62728\", fontweight='bold') # Usei o vermelho padrão do seaborn\n",
        "        l2 = ax_lr.plot(epochs, lrs, marker=\"\", linestyle=\"-.\", color=\"#d62728\", linewidth=1.5, label=\"Learning Rate\") # Mudei o marker e linestyle\n",
        "        ax_lr.tick_params(axis=\"y\", labelcolor=\"#d62728\")\n",
        "\n",
        "\n",
        "        ax_lr.set_yscale('log')\n",
        "\n",
        "        ax_lr.yaxis.set_major_formatter(\n",
        "            FuncFormatter(lambda y, _: f'{y:.0e}')\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "        # Legenda Unificada\n",
        "        lines = l1 + l2\n",
        "        labels = [l.get_label() for l in lines]\n",
        "        ax_loss.legend(lines, labels,\n",
        "                    loc='upper center',\n",
        "                    bbox_to_anchor=(0.5, 1.15),\n",
        "                    ncol=2,\n",
        "                    frameon=False,\n",
        "                    fontsize=10) # Ajustei o tamanho da fonte da legenda\n",
        "\n",
        "        fig.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        print(\"-\" * 80) # Linha separadora entre modelos\n",
        "\n",
        "plot_comparison(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85323b96",
      "metadata": {
        "id": "85323b96"
      },
      "source": [
        "## Inferência\n",
        "\n",
        "Calcule algumas métricas como acurácia, matriz de confusão, etc. Em seguida, teste o modelo em novas imagens das classes correspondentes mas de outras fontes (outro buscador, fotos próprias, etc)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21c63e2a",
      "metadata": {
        "id": "21c63e2a"
      },
      "outputs": [],
      "source": [
        "# Mapeamento: Sub-região visual -> Nação\n",
        "region_hierarchy = {\n",
        "    \"mondstadt\": \"Mondstadt\", \"dragonspine\": \"Mondstadt (Dragonspine)\",\n",
        "    \"liyue\": \"Liyue\",\n",
        "    \"inazuma\": \"Inazuma\", \"enkanomiya\": \"Inazuma (Enkanomiya)\",\n",
        "    \"sumeru\": \"Sumeru\", \"sumeru_desert\": \"Sumeru (Deserto)\",\n",
        "    \"fontaine\": \"Fontaine\", \"fontaine_underwater\": \"Fontaine (Debaixo d'água)\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "alkzOHPo6jPj",
      "metadata": {
        "id": "alkzOHPo6jPj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import torch\n",
        "\n",
        "def evaluate_complete(model, loader, class_names):\n",
        "    # --- 1. Obter Predições ---\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    print(\"Calculando métricas no Test Set...\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # --- Relatório em Texto  ---\n",
        "    print(\"\\n--- Relatório de Classificação ---\")\n",
        "    print(classification_report(all_labels, all_preds, target_names=class_names))\n",
        "\n",
        "    # --- 2. Preparar Dados ---\n",
        "    # Métricas\n",
        "    report_dict = classification_report(all_labels, all_preds, target_names=class_names, output_dict=True)\n",
        "    acc_score = report_dict['accuracy']\n",
        "\n",
        "    df_report = pd.DataFrame(report_dict).transpose()\n",
        "    classes_df = df_report.drop(['accuracy', 'macro avg', 'weighted avg'])\n",
        "\n",
        "    # Matriz\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "    # Configuração de fonte\n",
        "    TITLE_SIZE = 18    # Título principal\n",
        "    LABEL_SIZE = 18    # Nomes das regiões e eixos\n",
        "    ANNOT_SIZE = 18    # Números dentro do heatmap/barras\n",
        "\n",
        "    # ==========================================\n",
        "    # FIGURA 1: DASHBOARD DE MÉTRICAS (Heatmap + Barras)\n",
        "    # ==========================================\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, 9), gridspec_kw={'width_ratios': [2, 1]})\n",
        "\n",
        "    # --- Plot 1: Heatmap ---\n",
        "    sns.heatmap(classes_df[['precision', 'recall', 'f1-score']],\n",
        "                annot=True, cmap='RdYlGn', fmt='.2f', vmin=0.7, vmax=1.0,\n",
        "                cbar=False, ax=axes[0],\n",
        "                annot_kws={'size': ANNOT_SIZE}) # <--- Aumenta números internos\n",
        "\n",
        "    axes[0].set_title(f'Métricas por classe (Acurácia global: {acc_score:.2%})', fontsize=TITLE_SIZE, pad=15)\n",
        "\n",
        "    # Aumentar fontes dos eixos\n",
        "    axes[0].tick_params(axis='y', labelsize=LABEL_SIZE, rotation=0) # <--- Nomes das Regiões\n",
        "    axes[0].tick_params(axis='x', labelsize=LABEL_SIZE)             # <--- Precision/Recall...\n",
        "\n",
        "    # --- Plot 2: Barras de Support ---\n",
        "    sns.barplot(x=classes_df['support'], y=classes_df.index, ax=axes[1], color='skyblue', edgecolor='black')\n",
        "\n",
        "    axes[1].set_title('Qtd. Imagens (Support)', fontsize=TITLE_SIZE, pad=15)\n",
        "    axes[1].set_ylabel('')\n",
        "    axes[1].set_yticklabels([])\n",
        "    axes[1].tick_params(axis='x', labelsize=LABEL_SIZE)\n",
        "    axes[1].grid(axis='x', linestyle='--', alpha=0.6)\n",
        "\n",
        "    # Números na ponta das barras\n",
        "    for i, v in enumerate(classes_df['support']):\n",
        "        axes[1].text(v + 0.5, i, f\"{int(v)}\", color='black', va='center', fontweight='bold', fontsize=ANNOT_SIZE)\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # ==========================================\n",
        "    # FIGURA 2: MATRIZ DE CONFUSÃO\n",
        "    # ==========================================\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_names, yticklabels=class_names,\n",
        "                annot_kws={'size': ANNOT_SIZE})\n",
        "\n",
        "    plt.title('Matriz de Confusão', fontsize=TITLE_SIZE, pad=20)\n",
        "    plt.xlabel('Predito', fontsize=16)\n",
        "    plt.ylabel('Real', fontsize=16)\n",
        "    plt.xticks(rotation=90, fontsize=16)\n",
        "    plt.yticks(rotation=0, fontsize=16)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show() # Mostra o segundo gráfico\n",
        "\n",
        "\n",
        "    # ==============================================================================\n",
        "    # FIGURA 3: PRECISÃO POR REGIÃO (Com cores temáticas)\n",
        "    # ==============================================================================\n",
        "    # Definição das Cores Temáticas\n",
        "    genshin_colors = {\n",
        "        # --- Regras Específicas (Sub-regiões visuais distintas) ---\n",
        "        'Desert':      '#E6CC80',  # Cor de Areia (Para Sumeru Desert)\n",
        "        'Underwater':  '#00CED1',  # Turquesa Escuro (Para Fontaine Underwater)\n",
        "        'Dragonspine': '#B0E0E6',  # Azul Gelo Pálido\n",
        "        'Enkanomiya':  '#191970',  # Azul Meia-Noite (Bem escuro)\n",
        "\n",
        "        # --- Regras Gerais (Nações) ---\n",
        "        'Mondstadt':   '#4CC2A5',  # Anemo (Verde Água)\n",
        "        'Liyue':       '#FFCA3D',  # Geo (Amarelo Ouro)\n",
        "        'Inazuma':     '#9E77CB',  # Electro (Roxo)\n",
        "        'Sumeru':      '#74C25C',  # Dendro (Verde Folha - Pega o que sobrou de Sumeru)\n",
        "        'Fontaine':    '#4899E8',  # Hydro (Azul Claro - Pega o que sobrou de Fontaine)\n",
        "        'Natlan':      '#FF4500',  # Pyro (Laranja Avermelhado)\n",
        "    }\n",
        "\n",
        "    # 2. Lógica de Atribuição (Busca por Palavra-Chave)\n",
        "    bar_colors = []\n",
        "    for region_name in classes_df.index:\n",
        "        color_found = '#CCCCCC' # Cor padrão (Cinza) caso não ache nada\n",
        "\n",
        "        # O loop percorre o dicionário na ordem definida acima\n",
        "        for key, color in genshin_colors.items():\n",
        "            if key.lower() in region_name.lower():\n",
        "                color_found = color\n",
        "                break # <--- ACHOU A COR ESPECÍFICA? PARA DE PROCURAR.\n",
        "\n",
        "        bar_colors.append(color_found)\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # 3. Plotar SEM ordenar (usa a ordem original do classes_df)\n",
        "    sns.barplot(x=classes_df['precision'], y=classes_df.index, palette=bar_colors)\n",
        "\n",
        "    plt.title('Precisão por Região', fontsize=TITLE_SIZE, pad=15)\n",
        "    plt.xlabel('Precisão (0 a 1)', fontsize=14)\n",
        "    plt.xlim(0, 1.15)\n",
        "    plt.grid(axis='x', linestyle='--', alpha=0.3)\n",
        "\n",
        "    # 4. Colocar a porcentagem na frente de cada barra\n",
        "    for i, (val, name) in enumerate(zip(classes_df['precision'], classes_df.index)):\n",
        "        # Escolhe a cor do texto (preto ou a mesma cor da barra para ficar estiloso)\n",
        "        txt_color = '#333333'\n",
        "        plt.text(val + 0.01, i, f\"{val:.1%}\", va='center', fontsize=12, fontweight='bold', color=txt_color)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "iHxjH9I-ImZa",
      "metadata": {
        "id": "iHxjH9I-ImZa"
      },
      "outputs": [],
      "source": [
        "def visualize_grid(model, dataset, num_images=9, seed=None):\n",
        "    model.eval()\n",
        "\n",
        "    if seed is not None:\n",
        "        g = torch.Generator()\n",
        "        g.manual_seed(seed)\n",
        "        indices = torch.randperm(len(dataset), generator=g)[:num_images].tolist()\n",
        "    else:\n",
        "        indices = random.sample(range(len(dataset)), num_images)\n",
        "\n",
        "    plt.figure(figsize=(12, 12))\n",
        "\n",
        "    for i, idx in enumerate(indices):\n",
        "        img, label = dataset[idx]\n",
        "        input_tensor = img.unsqueeze(0).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(input_tensor)\n",
        "            prob = torch.nn.functional.softmax(output, dim=1)\n",
        "            conf, pred_idx = torch.max(prob, 1)\n",
        "\n",
        "        pred_class = dataset.classes[pred_idx.item()]\n",
        "        real_class = dataset.classes[label]\n",
        "\n",
        "        # Mapear para Nação\n",
        "        nation = region_hierarchy.get(pred_class, \"\")\n",
        "\n",
        "        # Cor: Verde se acertou, Vermelho se errou\n",
        "        color = 'green' if pred_class == real_class else 'red'\n",
        "\n",
        "        # Desnormalizar para exibir (assumindo ImageNet stats)\n",
        "        inv_norm = transforms.Normalize(\n",
        "            mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],\n",
        "            std=[1/0.229, 1/0.224, 1/0.225]\n",
        "        )\n",
        "        img_show = inv_norm(img).permute(1, 2, 0).cpu().numpy()\n",
        "        img_show = np.clip(img_show, 0, 1)\n",
        "\n",
        "        plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(img_show)\n",
        "        plt.axis('off')\n",
        "        plt.title(f\"Pred: {pred_class}\\nReal: {real_class}\\n{nation}\\n{conf.item():.1%}\",\n",
        "                  color=color, fontsize=10, fontweight='bold')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "T8NbnnU0Lnoq",
      "metadata": {
        "id": "T8NbnnU0Lnoq"
      },
      "outputs": [],
      "source": [
        "def visualize_uncertainty(model, dataset, num_images=5, seed=None):\n",
        "    model.eval()\n",
        "\n",
        "    # 1. Lógica de Sorteio (IGUAL AO GRID)\n",
        "    if seed is not None:\n",
        "        g = torch.Generator()\n",
        "        g.manual_seed(seed)\n",
        "        indices = torch.randperm(len(dataset), generator=g)[:num_images].tolist()\n",
        "    else:\n",
        "        indices = random.sample(range(len(dataset)), num_images)\n",
        "\n",
        "    # Parâmetros de denormalização\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "\n",
        "    print(f\"--- Visualização de Incerteza (Amostras: {indices}) ---\")\n",
        "\n",
        "    for i, idx in enumerate(indices):\n",
        "        # Pega a imagem direto do dataset pelo índice sorteado\n",
        "        img_tensor, label = dataset[idx]\n",
        "\n",
        "        # Prepara o batch de 1 imagem\n",
        "        input_tensor = img_tensor.unsqueeze(0).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_tensor)\n",
        "            probs = torch.nn.functional.softmax(outputs, dim=1)\n",
        "\n",
        "        # --- Plotagem ---\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "        # Imagem\n",
        "        img_show = img_tensor.cpu().numpy().transpose((1, 2, 0))\n",
        "        img_show = std * img_show + mean\n",
        "        img_show = np.clip(img_show, 0, 1)\n",
        "\n",
        "        real_class = dataset.classes[label]\n",
        "        ax1.imshow(img_show)\n",
        "        ax1.axis(\"off\")\n",
        "        ax1.set_title(f\"Real: {real_class}\\n(Índice {idx})\")\n",
        "\n",
        "        # Gráfico de Barras\n",
        "        p = probs[0].cpu().numpy()\n",
        "        predicted_idx = np.argmax(p)\n",
        "        pred_class = dataset.classes[predicted_idx]\n",
        "\n",
        "        # Cores\n",
        "        colors = [\"lightgray\"] * len(dataset.classes)\n",
        "        colors[label] = \"green\" # Correto\n",
        "        if predicted_idx != label:\n",
        "            colors[predicted_idx] = \"red\" # Erro\n",
        "\n",
        "        y_pos = np.arange(len(dataset.classes))\n",
        "        ax2.barh(y_pos, p, align='center', color=colors)\n",
        "        ax2.set_yticks(y_pos)\n",
        "        ax2.set_yticklabels(dataset.classes)\n",
        "        ax2.invert_yaxis()\n",
        "        ax2.set_xlabel('Probabilidade')\n",
        "        ax2.set_title(f\"Predição: {pred_class}\\n({p[predicted_idx]:.1%} certeza)\")\n",
        "        ax2.set_xlim(0, 1.1)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5OicH2OsIoux",
      "metadata": {
        "id": "5OicH2OsIoux"
      },
      "outputs": [],
      "source": [
        "# 1. Carregar o Melhor Modelo\n",
        "last_model_name = list(models_to_test.keys())[-1]\n",
        "print(f\"🔄 Carregando pesos do modelo: {last_model_name}...\")\n",
        "\n",
        "model_to_eval = models_to_test[last_model_name]\n",
        "model_to_eval.load_state_dict(torch.load(f\"best_model_{last_model_name}.pth\"))\n",
        "model_to_eval.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oY3uCFDOKHW5",
      "metadata": {
        "id": "oY3uCFDOKHW5"
      },
      "outputs": [],
      "source": [
        "# 2. Executar Métricas Gerais\n",
        "print(\"\\n=== AVALIAÇÃO GERAL ===\")\n",
        "evaluate_complete(model_to_eval, test_loader, train_dataset.classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a516551f",
      "metadata": {
        "id": "a516551f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0TXVC6O1Iaqa",
      "metadata": {
        "id": "0TXVC6O1Iaqa"
      },
      "outputs": [],
      "source": [
        "# 3. Executar Visualização em Grid\n",
        "print(\"\\n=== EXEMPLOS VISUAIS ===\")\n",
        "visualize_grid(model_to_eval, test_dataset, num_images=6, seed=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MghRUSQALrK4",
      "metadata": {
        "id": "MghRUSQALrK4"
      },
      "outputs": [],
      "source": [
        "# --- NOVA CHAMADA ---\n",
        "# Note que agora passamos apenas o 'test_dataset', não mais o 'loader'\n",
        "print(\"\\n=== ANÁLISE DE INCERTEZA (Amostras Aleatórias) ===\")\n",
        "visualize_uncertainty(model_to_eval, test_dataset, num_images=3, seed=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xrUmdSmrLhSU",
      "metadata": {
        "id": "xrUmdSmrLhSU"
      },
      "outputs": [],
      "source": [
        "def predict_genshin(image_path, real_label=None):\n",
        "    # Carregar e transformar\n",
        "    try:\n",
        "        img = Image.open(image_path).convert('RGB')\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao abrir imagem: {e}\")\n",
        "        return\n",
        "\n",
        "    # Usa a mesma transformação de validação/teste\n",
        "    img_t = val_test_transforms(img).unsqueeze(0).to(device)\n",
        "\n",
        "    model_to_eval.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model_to_eval(img_t)\n",
        "        probs = torch.nn.functional.softmax(outputs, dim=1)\n",
        "        conf, idx = torch.max(probs, 1)\n",
        "\n",
        "    pred_class = train_dataset.classes[idx.item()]\n",
        "    pred_nation = region_hierarchy.get(pred_class, \"Desconhecido\")\n",
        "\n",
        "    plt.figure(figsize=(5,5))\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "\n",
        "    title_text = f\"Predito: {pred_class.upper()} ({pred_nation})\"\n",
        "    color = 'black'\n",
        "\n",
        "    if real_label:\n",
        "        title_text += f\"\\nReal: {real_label.upper()}\"\n",
        "        color = 'green' if real_label == pred_class else 'red'\n",
        "\n",
        "    title_text += f\"\\nConfiança: {conf.item():.1%}\"\n",
        "    plt.title(title_text, color=color, fontweight='bold')\n",
        "    plt.show()\n",
        "\n",
        "def test_random_local_image():\n",
        "    if not os.path.exists(TEST_DIR):\n",
        "        print(\"Pasta de teste não encontrada.\")\n",
        "        return\n",
        "\n",
        "    # Sorteia classe e imagem\n",
        "    random_class = random.choice(os.listdir(TEST_DIR))\n",
        "    class_path = os.path.join(TEST_DIR, random_class)\n",
        "\n",
        "    try:\n",
        "        random_image = random.choice(os.listdir(class_path))\n",
        "        full_path = os.path.join(class_path, random_image)\n",
        "        print(f\"Testando imagem local: {random_image}\")\n",
        "        predict_genshin(full_path, real_label=random_class)\n",
        "    except IndexError:\n",
        "        print(f\"A pasta {random_class} parece vazia.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5j5guO7DMSs_",
      "metadata": {
        "id": "5j5guO7DMSs_"
      },
      "outputs": [],
      "source": [
        "def predict_from_root():\n",
        "    root_folder = \"/content\"\n",
        "    # Extensões válidas\n",
        "    valid_extensions = ('.jpg', '.jpeg', '.png', '.webp', '.bmp')\n",
        "\n",
        "    print(f\"--- Varrendo apenas a raiz ({root_folder}) ---\")\n",
        "\n",
        "    files_found = 0\n",
        "\n",
        "    # Lista tudo na pasta raiz\n",
        "    for filename in os.listdir(root_folder):\n",
        "        full_path = os.path.join(root_folder, filename)\n",
        "\n",
        "        # A MÁGICA ESTÁ AQUI:\n",
        "        # 1. Verifica se é arquivo (ignora pastas!)\n",
        "        # 2. Verifica se tem extensão de imagem\n",
        "        if os.path.isfile(full_path) and filename.lower().endswith(valid_extensions):\n",
        "\n",
        "            # Filtro extra: Ignorar arquivos de sistema do Colab (opcional)\n",
        "            if filename == \"best_model.pth\": continue\n",
        "\n",
        "            print(f\"\\n📸 Encontrado: {filename}\")\n",
        "            try:\n",
        "                # Chama a função de predição que já criamos\n",
        "                predict_genshin(full_path)\n",
        "                files_found += 1\n",
        "            except Exception as e:\n",
        "                print(f\"Erro ao ler arquivo: {e}\")\n",
        "\n",
        "    if files_found == 0:\n",
        "        print(\">> Nenhuma imagem solta encontrada na raiz!\")\n",
        "        print(\">> Arraste os arquivos para a área lateral esquerda (fora de pastas).\")\n",
        "\n",
        "# Executar\n",
        "predict_from_root()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cada6637",
      "metadata": {
        "id": "cada6637"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "root_folder = \"/content\"\n",
        "\n",
        "print(f\"--- Deletando arquivos .png começando com '2025' na raiz ({root_folder}) ---\")\n",
        "\n",
        "deleted_count = 0\n",
        "for filename in os.listdir(root_folder):\n",
        "    if filename.startswith('2025') and filename.lower().endswith('.png') and os.path.isfile(os.path.join(root_folder, filename)):\n",
        "        full_path = os.path.join(root_folder, filename)\n",
        "        try:\n",
        "            os.remove(full_path)\n",
        "            print(f\"🗑️ Deletado: {filename}\")\n",
        "            deleted_count += 1\n",
        "        except Exception as e:\n",
        "            print(f\"Erro ao deletar {filename}: {e}\")\n",
        "\n",
        "if deleted_count == 0:\n",
        "    print(\">> Nenhuma imagem .png começando com '2025' foi encontrada para deletar.\")\n",
        "else:\n",
        "    print(f\"\\nTotal de arquivos deletados: {deleted_count}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}